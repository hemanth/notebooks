{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrewAI with Remote MCP Connection Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use CrewAI to connect to a remote MCP (Model Context Protocol) server and utilize its tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install crewai 'crewai-tools[mcp]' python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries and set up environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import MCPServerAdapter\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Placeholder for OPENAI_API_KEY or other LLM provider keys\n",
    "# Ensure you have a .env file in the root of this repository with your API key\n",
    "# For example:\n",
    "# OPENAI_API_KEY=\"sk-...\" \n",
    "# OPENAI_MODEL_NAME=\"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure MCP Server Connection\n",
    "\n",
    "You need to define the connection parameters for your remote MCP server.\n",
    "This typically involves specifying the URL and the transport mechanism (`streamable-http` or `sse`).\n",
    "\n",
    "**Example using a local Streamable HTTP server (like `hello_http_server.py` from the `crewai-mcp-demo` repository):**\n",
    "If you were running the `hello_http_server.py` from the demo, it would be:\n",
    "`server_params = {\"url\": \"http://localhost:8001/mcp\", \"transport\": \"streamable-http\"}`\n",
    "\n",
    "**For your actual remote MCP server, replace the values below with your server's details.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Configure these parameters for your remote MCP server\n",
    "# Option 1: Streamable HTTP\n",
    "server_params = {\n",
    "    \"url\": \"YOUR_REMOTE_MCP_SERVER_URL/mcp\",  # Replace with your server's URL (often ends with /mcp)\n",
    "    \"transport\": \"streamable-http\"\n",
    "}\n",
    "\n",
    "# Option 2: SSE\n",
    "# server_params = {\n",
    "#     \"url\": \"YOUR_REMOTE_MCP_SSE_ENDPOINT_URL\",  # Replace with your server's SSE endpoint URL\n",
    "#     \"transport\": \"sse\" # SSE transport typically doesn't need 'transport' explicitly if URL is specific\n",
    "# }\n",
    "\n",
    "# Example for testing with a local dummy server (if you have one running, e.g., hello_http_server.py)\n",
    "# server_params = {\"url\": \"http://localhost:8001/mcp\", \"transport\": \"streamable-http\"}\n",
    "\n",
    "print(f\"MCP Server Params: {server_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Agent and Task to Use MCP Tools\n",
    "\n",
    "Now we'll create a CrewAI agent and provide it with the tools made available by the MCP server.\n",
    "The task will instruct the agent to use one of these tools.\n",
    "\n",
    "**Note:** The agent's role, goal, backstory, and the task's description will be generic. \n",
    "You should customize these based on the actual capabilities of your MCP server and the tools it provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for agent and task definitions\n",
    "# We'll attempt to connect to the MCP server and list its tools first.\n",
    "# If successful, we'll define an agent that uses these tools.\n",
    "\n",
    "mcp_agent = None\n",
    "mcp_task = None\n",
    "\n",
    "try:\n",
    "    with MCPServerAdapter(server_params) as mcp_tools:\n",
    "        available_tools = [tool.name for tool in mcp_tools]\n",
    "        print(f\"Available tools from MCP server: {available_tools}\")\n",
    "\n",
    "        if not mcp_tools:\n",
    "            print(\"No tools found or connection failed. Please check your MCP server and `server_params`.\")\n",
    "            print(\"Skipping agent and task creation.\")\n",
    "        else:\n",
    "            # Define an agent that uses the MCP tools\n",
    "            mcp_agent = Agent(\n",
    "                role=\"Remote Service Interactor\",\n",
    "                goal=f\"Utilize tools from the MCP server at {server_params.get('url')} to accomplish tasks.\",\n",
    "                backstory=\"I am an AI agent designed to connect to remote MCP servers and leverage their functionalities through CrewAI.\",\n",
    "                tools=mcp_tools,  # Assign the fetched MCP tools to the agent\n",
    "                allow_delegation=False,\n",
    "                verbose=True,\n",
    "                # Optional: configure LLM if not using default OpenAI\n",
    "                # llm=OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"), model_name=os.getenv(\"OPENAI_MODEL_NAME\")) \n",
    "            )\n",
    "\n",
    "            # Define a task for the agent\n",
    "            # TODO: Customize the task description and expected_output based on your MCP server's tools and desired action.\n",
    "            # You might want to prompt the user for the tool name and specific inputs.\n",
    "            # For this example, we'll make a generic task. If specific tools are known, it's better to be explicit.\n",
    "            \n",
    "            task_description = \"Access the remote MCP server and list the available high-level capabilities or perform a default action.\"\n",
    "            expected_output = \"A summary of capabilities or the result of the default action from the MCP server.\"\n",
    "\n",
    "            if available_tools:\n",
    "                # If specific tools are discovered, you could make the task more targeted.\n",
    "                # For example, if a 'get_status' tool exists:\n",
    "                # task_description = f\"Use the '{available_tools[0]}' tool to get the current status from the MCP server.\"\n",
    "                # expected_output = \"The current status information from the MCP server.\"\n",
    "                # For now, let's assume the agent will figure out how to interact based on the generic tools.\n",
    "                task_description = f\"Interact with the MCP server using one of its available tools ({', '.join(available_tools)}) to get a general status or introductory message.\"\n",
    "                expected_output = \"A response from the MCP server based on the interaction.\"\n",
    "\n",
    "\n",
    "            mcp_task = Task(\n",
    "                description=task_description,\n",
    "                expected_output=expected_output,\n",
    "                agent=mcp_agent\n",
    "            )\n",
    "            \n",
    "            print(\"Agent and Task defined successfully.\")\n",
    "            print(f\"Agent: {mcp_agent.role}\")\n",
    "            print(f\"Task: {mcp_task.description}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while trying to connect to the MCP server or define the agent/task: {e}\")\n",
    "    print(\"Please ensure your MCP server is running and `server_params` are correctly configured.\")\n",
    "    print(\"If you are using a local server for testing (e.g., from crewai-mcp-demo), make sure it's started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handling Connection, Authentication, and Errors\n",
    "\n",
    "The `MCPServerAdapter` handles the basic connection to the MCP server using the `server_params` you provide. The `try...except` block in the previous step is set up to catch common issues like:\n",
    "*   The MCP server being unreachable.\n",
    "*   Incorrect `server_params` (e.g., wrong URL or transport type).\n",
    "*   Issues during the MCP handshake.\n",
    "\n",
    "**Authentication:**\n",
    "\n",
    "*   If your remote MCP server requires authentication (e.g., API keys, tokens), the method for providing these credentials depends on the MCP server's implementation and the tools it exposes.\n",
    "*   **Tool-Based Authentication:** Some tools might accept credentials as part of their input schema when they are called by the agent. You would need to understand the specific requirements of your MCP server's tools.\n",
    "*   **Custom Headers/Parameters:** If the MCP server expects authentication information via HTTP headers (like an `Authorization` header) or specific query parameters, and if the `MCPServerAdapter` or the underlying MCP client library supports passing these through `server_params`, you would include them there. The current `crewai-tools` documentation for `MCPServerAdapter` doesn't explicitly detail adding custom headers for HTTP/SSE transports directly in `server_params`. This might require the MCP server itself to be designed to accept auth through standard mechanisms its tools can access, or potentially a more advanced setup if direct header injection via the adapter is needed but not supported.\n",
    "*   **Environment Variables:** For sensitive data like API keys, always prefer using environment variables (as shown for the LLM API key) and have your MCP tool or server retrieve them securely.\n",
    "\n",
    "Ensure your MCP server is configured to handle authentication appropriately and that your CrewAI agent/task provides any necessary credentials in a secure manner, likely when invoking a specific tool that requires them.\n",
    "\n",
    "The notebook will proceed to define a Crew and attempt to run it. If the connection failed or no tools were found in the previous step, the `mcp_agent` and `mcp_task` will be `None`, and the Crew execution will be skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the Crew and Demonstrate Interaction\n",
    "\n",
    "If the MCP server connection was successful and the agent and task were defined, we can now create a Crew and run it.\n",
    "The crew will execute the task, which involves the agent using the tools from the remote MCP server.\n",
    "\n",
    "**Note:** The actual interaction and output will depend heavily on:\n",
    "1.  Your MCP server's tools and how they respond.\n",
    "2.  The LLM's ability to understand how to use the provided tools based on their descriptions.\n",
    "3.  The specifics of the task you defined for the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only proceed if the agent and task were successfully created\n",
    "if mcp_agent and mcp_task:\n",
    "    # Create the crew\n",
    "    mcp_crew = Crew(\n",
    "        agents=[mcp_agent],\n",
    "        tasks=[mcp_task],\n",
    "        process=Process.sequential,  # Sequential process for this example\n",
    "        verbose=2  # Provides detailed output of the crew's execution\n",
    "    )\n",
    "\n",
    "    # Kick off the crew's execution\n",
    "    # TODO: If your task requires specific inputs, provide them in the `inputs` dictionary.\n",
    "    # For the generic task defined, we might not need specific inputs, \n",
    "    # but if your customized task uses placeholders like {topic}, provide them here.\n",
    "    # Example: inputs={\"topic\": \"general status\"}\n",
    "    print(\"\\nStarting Crew execution...\")\n",
    "    try:\n",
    "        result = mcp_crew.kickoff(inputs={}) # Add inputs if your task requires them\n",
    "        \n",
    "        print(\"\\n--------------------------------------------------\")\n",
    "        print(\"Crew Execution Finished.\")\n",
    "        print(\"Result from MCP interaction via CrewAI:\")\n",
    "        print(result)\n",
    "        print(\"--------------------------------------------------\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during crew execution: {e}\")\n",
    "        print(\"This could be due to issues with the LLM, the tools themselves, or the way the task is defined.\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping Crew execution because the agent and/or task were not properly initialized.\")\n",
    "    print(\"Please check previous steps for errors, especially MCP server connection and tool discovery.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Next Steps\n",
    "\n",
    "This notebook has demonstrated the foundational steps to connect CrewAI to a remote MCP server:\n",
    "\n",
    "1.  **Setup:** Installing necessary libraries (`crewai`, `crewai-tools[mcp]`).\n",
    "2.  **Configuration:**\n",
    "    *   Setting up environment variables for LLM API keys (e.g., `OPENAI_API_KEY`).\n",
    "    *   Defining `server_params` with your remote MCP server's URL and transport mechanism. This is a **critical step** for you to customize.\n",
    "3.  **MCP Connection & Tool Integration:**\n",
    "    *   Using `MCPServerAdapter` to connect to your MCP server and automatically make its tools available to CrewAI.\n",
    "4.  **Agent and Task Definition:**\n",
    "    *   Creating a CrewAI `Agent` equipped with the tools from your MCP server.\n",
    "    *   Defining a `Task` that instructs the agent on what to achieve using these tools.\n",
    "    *   Both the agent (role, goal, backstory) and task (description, expected_output) are generic in this sample and **must be customized** to match your MCP server's capabilities and your specific objectives. The more descriptive your tool names and descriptions are on the MCP server, and the clearer your task is, the better the LLM will be at using them.\n",
    "5.  **Crew Execution:**\n",
    "    *   Forming a `Crew` and `kickoff()` its execution to see the agent interact with the MCP server.\n",
    "    *   The results depend on the successful integration and the nature of the tools on your MCP server.\n",
    "\n",
    "**Key Customization Points for You:**\n",
    "\n",
    "*   **`server_params`**: Update this with your actual remote MCP server details.\n",
    "*   **Agent Definition**: Tailor the `role`, `goal`, and `backstory` of the `mcp_agent`.\n",
    "*   **Task Definition**: Modify the `description` and `expected_output` of the `mcp_task` to be specific to what you want to achieve with your MCP server's tools. If your task requires inputs, provide them in the `crew.kickoff(inputs={...})` call.\n",
    "*   **LLM Configuration**: If you're not using OpenAI or want to specify a different model, configure the `llm` parameter when creating your `Agent`.\n",
    "*   **Authentication**: Ensure any authentication required by your MCP server is handled (as discussed in section 3).\n",
    "\n",
    "By modifying these sections, you can adapt this notebook to work with your specific remote MCP environment. Remember to consult the documentation for your MCP server to understand the tools it provides and how to interact with them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
